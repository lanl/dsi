{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc40f15-82c6-4bfc-a629-cb023afa3a3f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f80ba9-0f82-4c55-a5ae-6a09b8540730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io, contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d102c-8609-47e6-a8ab-9b0aec4d9e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install in your environment; do only once\n",
    "!{sys.executable} -m pip install langchain openai\n",
    "!{sys.executable} -m pip install langchain_community openai\n",
    "!{sys.executable} -m pip install langchain_experimental\n",
    "!{sys.executable} -m pip install --upgrade langchain langchain_community openai\n",
    "!{sys.executable} -m pip install --upgrade langchain langchain-openai openai\n",
    "!{sys.executable} -m pip install -U langchain-ollama\n",
    "!{sys.executable} -m pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfcd80-f0b7-4690-8dd2-7ca7a47ccb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5251a2a6-1ef1-4d45-9299-b14aea7b76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsi.dsi import DSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6623f4-8d71-4035-8066-b9a3bf1ad947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96841c0c-9a8f-4f1b-b526-ce5e5392302e",
   "metadata": {},
   "source": [
    "## AI Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acdfea-4ace-4d8a-95d0-2bec692179e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to ask chatgpt for queries\n",
    "def ask_chatgpt_for_sql(store, user_request, open_ai_key, model_name=\"gpt-5\"):\n",
    "    # Get schema\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf):\n",
    "        if store.backend_name == 'sqlite':\n",
    "            store.query(\"SELECT name, type, sql FROM sqlite_master WHERE sql NOT NULL ORDER BY type, name\")\n",
    "        else:\n",
    "            store.query(\"SELECT table_name AS name, table_type AS type FROM information_schema.tables WHERE table_schema = 'main' ORDER BY table_type, table_name\")\n",
    "    query_output_str = buf.getvalue()\n",
    "    schema = query_output_str.rsplit(\"|\", 1)[-1].strip()\n",
    "    \n",
    "    # Set key\n",
    "    os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "    \n",
    "    # Use LLM to extract queries\n",
    "    prompt_template = (\n",
    "        \"You are an expert in SQL assistant.\\n\"\n",
    "        \"Here is the schema:\\n{schema}\\n\\n\"\n",
    "        \"Generate a SQL query for the following request:\\n{user_request}\\n\\n\"\n",
    "        \"Only output the SQL query on one line please.\"\n",
    "    )\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"schema\", \"user_request\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=0)\n",
    "    \n",
    "    # Create the chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\n",
    "        \"schema\": schema, \n",
    "        \"user_request\": user_request\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d5a00-ff13-445a-a31d-05e2c52114c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama_for_sql(store, user_request, model_name=\"mistral:latest\"):\n",
    "    # Get schema\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf):\n",
    "        if store.backend_name == 'sqlite':\n",
    "            store.query(\"SELECT name, type, sql FROM sqlite_master WHERE sql NOT NULL ORDER BY type, name\")\n",
    "        else:\n",
    "            store.query(\"SELECT table_name AS name, table_type AS type FROM information_schema.tables WHERE table_schema = 'main' ORDER BY table_type, table_name\")\n",
    "    query_output_str = buf.getvalue()\n",
    "    schema = query_output_str.rsplit(\"|\", 1)[-1].strip()\n",
    "\n",
    "    # Use LLM to extract queries\n",
    "    prompt_template = (\n",
    "        \"You are an expert SQL assistant.\\n\"\n",
    "        \"Here is the schema:\\n{schema}\\n\\n\"\n",
    "        \"Generate a SQL query for the following request:\\n{user_request}\\n\\n\"\n",
    "        \"Only output the SQL query on one line please.\"\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"schema\", \"user_request\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "\n",
    "    # Initialize the local chat model served by Ollama\n",
    "    llm = ChatOllama(model=model_name, temperature=0)\n",
    "\n",
    "    # LCEL chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # NOTE: your original snippet had {user_query}; use user_request instead.\n",
    "    response = chain.invoke({\n",
    "        \"schema\": schema,\n",
    "        \"user_request\": user_request\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "212be803-a4f1-47bf-8f40-af6773642cee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdd15ea-bc34-4960-b848-97cd9a28d1a3",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d50037-0ff0-4ddf-8861-1753847627fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created an instance of DSI\n"
     ]
    }
   ],
   "source": [
    "store = DSI(backend_name = \"Sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c58d6-ab91-4601-b2a1-17ded4b7ee2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4451bb-b19a-4629-9822-7ad49062725c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded wildfire/wildfiredata.csv into the table wildfiredata\n"
     ]
    }
   ],
   "source": [
    "store.read(\"wildfire/wildfiredata.csv\", 'CSV', table_name='wildfiredata')\n",
    "#store.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acf5e3f-f62e-487d-a1b7-c6f438adf1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DSI in module dsi.dsi object:\n",
      "\n",
      "class DSI(builtins.object)\n",
      " |  DSI(filename='.temp.db', backend_name='Sqlite', **kwargs)\n",
      " |  \n",
      " |  A user-facing interface for DSI's Core middleware.\n",
      " |  \n",
      " |  The DSI Class abstracts Core.Terminal for managing metadata and Core.Sync for data management and movement.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filename='.temp.db', backend_name='Sqlite', **kwargs)\n",
      " |      Initializes DSI by activating a backend for data operations; default is a Sqlite backend for temporary data analysis.\n",
      " |      If users specify `filename`, data is saved to a permanent backend file.\n",
      " |      Can now call read(), find(), update(), query(), write() or any backend printing operations\n",
      " |      \n",
      " |      `filename` : str, optional\n",
      " |          If not specified, a temporary, hidden backend file is created for users to analyze their data.\n",
      " |          If specified and backend file already exists, it is activated for a user to explore its data.\n",
      " |          If specified and backend file does not exist, a file with this name is created.\n",
      " |          \n",
      " |          Accepted file extensions:\n",
      " |              - If backend_name = \"Sqlite\" → .db, .sqlite, .sqlite3\n",
      " |              - If backend_name = \"DuckDB\" → .duckdb, .db\n",
      " |          \n",
      " |      `backend_name` : str, optional\n",
      " |          Name of the backend to activate. Must be either \"Sqlite\" or \"DuckDB\" or \"SqlAlchemyMySQL\".\n",
      " |          Default is \"Sqlite\".\n",
      " |  \n",
      " |  close(self)\n",
      " |      Closes the connection to the active backend and clears all loaded DSI modules.\n",
      " |  \n",
      " |  display(self, table_name, num_rows=25, display_cols=None)\n",
      " |      Prints data from a specified table in the active backend.\n",
      " |      \n",
      " |      `table_name` : str\n",
      " |          Name of the table to display.\n",
      " |       \n",
      " |      `num_rows` : int, optional, default=25\n",
      " |          Maximum number of rows to print. If the table contains fewer rows, only those are shown.\n",
      " |      \n",
      " |      `display_cols` : list of str, optional\n",
      " |          List of specific column names to display from the table. \n",
      " |      \n",
      " |          If None (default), all columns are displayed.\n",
      " |  \n",
      " |  fetch(self, fname)\n",
      " |  \n",
      " |  find(self, query, collection=False, update=False)\n",
      " |      Finds all rows in the table where a column-level condition (e.g., \"age > 4\") is satisfied.\n",
      " |      \n",
      " |      `query` : str\n",
      " |          A column-level condition that must be in the format of a [column name] [operator] [value]. \n",
      " |          The value can be a string or number. Valid operators as example queries:\n",
      " |          \n",
      " |          - age > 4 \n",
      " |          - age < 4 \n",
      " |          - age >= 4 \n",
      " |          - age <= 4 \n",
      " |          - age = 4 \n",
      " |          - age == 4\n",
      " |          - age ~ 4    --> column age contains the number 4\n",
      " |          - age ~~ 4   --> column age contains the number 4\n",
      " |          - age != 4 \n",
      " |          - age (4, 8) --> all values in 'age' between 4 and 8 (inclusive)\n",
      " |      \n",
      " |      `collection` : bool, optional, default False.\n",
      " |          If True, returns a pandas DataFrame representing a subset of table rows that satisfy the `query`.\n",
      " |          \n",
      " |          If False (default), prints the result.\n",
      " |      \n",
      " |      `update` : bool, optional, default False.\n",
      " |          If True, includes 'dsi_table_name' and 'dsi_row_index' columns required for ``dsi.update()``.\n",
      " |      \n",
      " |          If False (default), return object does not include these columns.\n",
      " |      \n",
      " |      `return` : If there are no matches found, then nothing is returned or printed\n",
      " |  \n",
      " |  get(self, dbname)\n",
      " |      #help, edge-finding (find this/that)\n",
      " |  \n",
      " |  get_table(self, table_name, collection=False, update=False)\n",
      " |      Retrieves all data from a specified table without requiring knowledge of the active backend's query language.\n",
      " |      \n",
      " |      This method offers a simplified alternative to `query()` for retrieving a full table data without using SQL.\n",
      " |      \n",
      " |      `table_name` : str\n",
      " |          Name of the table from which all data will be retrieved.\n",
      " |      \n",
      " |      `collection` : bool, optional, default False.\n",
      " |          If True, returns the result as a pandas DataFrame.\n",
      " |          \n",
      " |          If False (default), prints the result.\n",
      " |      \n",
      " |      `update` : bool, optional, default False.\n",
      " |          If True, includes a 'dsi_table_name' column required for ``dsi.update()``. \n",
      " |      \n",
      " |          If False (default), return object does not include this column.\n",
      " |      \n",
      " |      `return`: If `table_name` does not exist in the backend, then nothing is returned or printed\n",
      " |  \n",
      " |  list(self, collection=False)\n",
      " |      Gets the names and dimensions (rows x columns) of all tables in the active backend.\n",
      " |      \n",
      " |      `collection` : bool, optional, default False. \n",
      " |          If True, returns a Python list of all the table names\n",
      " |          \n",
      " |          If False (default), prints each table's name and dimensions to the console.\n",
      " |  \n",
      " |  list_backends(self)\n",
      " |      Prints a list of valid backends that can be used in the `backend_name` argument in `backend()`\n",
      " |  \n",
      " |  list_readers(self)\n",
      " |      Prints a list of valid readers that can be used in the `reader_name` argument in `read()`\n",
      " |  \n",
      " |  list_writers(self)\n",
      " |      Prints a list of valid writers that can be used in the `writer_name` argument in `write()`\n",
      " |  \n",
      " |  move(self, filepath)\n",
      " |  \n",
      " |  num_tables(self)\n",
      " |      Prints the number of tables in the active backend.\n",
      " |  \n",
      " |  query(self, statement, collection=False, update=False)\n",
      " |      Executes a SQL query on the active backend.\n",
      " |      \n",
      " |      `statement` : str\n",
      " |          A SQL query to execute. Only `SELECT` and `PRAGMA` statements are allowed.\n",
      " |      \n",
      " |      `collection` : bool, optional, default False.\n",
      " |          If True, returns the result as a pandas DataFrame.\n",
      " |          \n",
      " |          If False (default), prints the result.\n",
      " |      \n",
      " |      `update` : bool, optional, default False.\n",
      " |          If True, includes a 'dsi_table_name' column required for ``dsi.update()``. \n",
      " |      \n",
      " |          If False (default), return object does not include this column.\n",
      " |      \n",
      " |      `return`: If the `statement` is incorrectly formatted, then nothing is returned or printed\n",
      " |  \n",
      " |  read(self, filenames, reader_name, table_name=None)\n",
      " |      Loads data into DSI using the specified parameter `reader_name`\n",
      " |      \n",
      " |      `filenames` : str or list of str or data object\n",
      " |          Either file path(s) to the data file(s) or an in-memory data object.\n",
      " |      \n",
      " |          The expected input type depends on the selected `reader_name`:\n",
      " |              - \"Collection\"           → Ordered Dictionary of table(s)\n",
      " |              - \"CSV\"                  → .csv\n",
      " |              - \"Parquet\"              → .pq\n",
      " |              - \"YAML1\"                → .yaml or .yml\n",
      " |              - \"TOML1\"                → .toml\n",
      " |              - \"JSON\"                 → .json\n",
      " |              - \"Ensemble\"             → .csv\n",
      " |              - \"Cloverleaf\"           → /path/to/data/directory/\n",
      " |              - \"Bueno\"                → .data\n",
      " |              - \"DublinCoreDatacard\"   → .xml\n",
      " |              - \"SchemaOrgDatacard\"    → .json\n",
      " |              - \"GoogleDatacard\"       → .yaml or .yml\n",
      " |              - \"Oceans11Datacard\"     → .yaml or .yml\n",
      " |      \n",
      " |      `reader_name` : str\n",
      " |          Name of the DSI Reader to use for loading the data. \n",
      " |      \n",
      " |          If using a DSI-supported Reader, this should be one of the reader_names from `list_readers()`.\n",
      " |      \n",
      " |          If using a custom Reader, provide the relative file path to the Python script with the Reader.  \n",
      " |          For guidance on creating a DSI-compatible Reader, view :ref:`custom_reader`.\n",
      " |      \n",
      " |      `table_name` : str, optional\n",
      " |          Name to assign to the loaded table.\n",
      " |      \n",
      " |          Required when using the `Collection` reader to load an Ordered Dictionary representing only one table.\n",
      " |          \n",
      " |          Recommended when the input file contains a single table for the `CSV`, `Parquet`, `JSON`, or `Ensemble` reader.\n",
      " |  \n",
      " |  schema(self, filename)\n",
      " |      Loads a relational database schema into DSI from a specified `filename`\n",
      " |      \n",
      " |       `filename` : str\n",
      " |           Path to a JSON file describing the structure of a relational database.\n",
      " |           The schema should follow the format described in :ref:`user_schema_example_label`\n",
      " |      \n",
      " |       **Must be called before reading in any data files associated with the schema**\n",
      " |  \n",
      " |  search(self, query, collection=False)\n",
      " |      Finds all rows across all tables in the active backend where `query` can be found.\n",
      " |      \n",
      " |      `query` : int, float, or str\n",
      " |          The value to search for in all rows across all tables.\n",
      " |      \n",
      " |      `collection` : bool, optional, default False. \n",
      " |          If True, returns a list of pandas DataFrames representing a subset of tables where `query` is found.\n",
      " |      \n",
      " |          If False (default), prints the matches to the console.\n",
      " |  \n",
      " |  summary(self, table_name=None, collection=False)\n",
      " |      Prints numerical metadata and (optionally) sample data from tables in the active backend.\n",
      " |      \n",
      " |      `table_name` : str, optional\n",
      " |          If specified, only the numerical metadata for that table will be printed.\n",
      " |          \n",
      " |          If None (default), metadata for all available tables is printed.\n",
      " |      \n",
      " |      `collection` : bool, optional, default False. \n",
      " |          If True, and table_name specified, returns a Pandas DataFrame of the summary of that table.\n",
      " |      \n",
      " |          If True, and table_name not specified, returns a list of Pandas DataFrames of the summary of all tables.\n",
      " |          \n",
      " |          If False (default), prints each table's name and dimensions to the console.\n",
      " |  \n",
      " |  update(self, collection, backup=False)\n",
      " |      Updates data in one or more tables in the active backend using the provided input. \n",
      " |      Intended to be used after modifying the output of `find()`, `search()`, `query()`, or `get_table()`\n",
      " |      \n",
      " |      `collection` : pandas.DataFrame\n",
      " |          The data used to update a table. \n",
      " |          DataFrame must include unchanged **`dsi_`** columns from `find()`, `search()`, `query()` or `get_table()` to successfully update.\n",
      " |      \n",
      " |          - If a `query()` DataFrame is the input, the corresponding table in the backend will be completely overwritten.\n",
      " |      \n",
      " |      `backup` : bool, optional, default False. \n",
      " |          If True, creates a backup file for the DSI backend before updating its data.\n",
      " |      \n",
      " |          If False (default), only updates the data.\n",
      " |      \n",
      " |      - NOTE: Columns from the original table cannot be deleted during update. Only row edits or column additions are allowed.\n",
      " |      - NOTE: If update() affects a user-defined primary key column, row order may change upon reinsertion.\n",
      " |  \n",
      " |  write(self, filename, writer_name, table_name=None)\n",
      " |      Exports data from the active backend using the specified `writer_name`.\n",
      " |      \n",
      " |      `filename` : str\n",
      " |          Name of the output file to write.\n",
      " |      \n",
      " |          Expected file extensions based on `writer_name`:\n",
      " |              - \"ER_Diagram\"   → .png, .pdf, .jpg, .jpeg\n",
      " |              - \"Table_Plot\"   → .png, .jpg, .jpeg\n",
      " |              - \"Csv\"          → .csv\n",
      " |              - \"Parquet\"      → .pq\n",
      " |      \n",
      " |      `writer_name` : str        \n",
      " |          Name of the DSI Writer to export data. \n",
      " |          \n",
      " |          If using a DSI-supported Writer, this should be one of the writer_names from `list_writers()`.\n",
      " |      \n",
      " |          If using a custom Writer, provide the relative file path to the Python script with the Writer.  \n",
      " |          For guidance on creating a DSI-compatible Writer, view :ref:`custom_writer`.\n",
      " |      \n",
      " |      `table_name`: str, optional\n",
      " |          Required when using \"Table_Plot\", \"Csv\" or \"Parquet\" to specify which table to export.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349d3558-2477-4e00-b011-54c5ccd40354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database now has 1 table\n"
     ]
    }
   ],
   "source": [
    "store.num_tables()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53e84be7-84a9-4241-b4e6-9dc9e1dbd1e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13c00094-1956-4359-9644-8dc186db89e5",
   "metadata": {},
   "source": [
    "# Use AI to extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ee0a8-3030-4199-8f24-4f5a251ce056",
   "metadata": {},
   "source": [
    "## Use AI for SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aec268-76ac-44f2-868d-9f633cf231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Find all entries where wind speed is above 10\"\n",
    "sql_query_1 = ask_chatgpt_for_sql(store, user_question, os.getenv(\"OPENAI_API_KEY\"),  model_name=\"gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade020ef-65a1-4c5d-8521-cccfe5b08dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store.query(sql_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce549548-b383-40cf-b4f4-106f79499145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3fe36-84c1-4e60-bb66-8ba352407738",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Find all entries where wind speed is above 10 and show it in ascending order of burned area size, and show only the top 5\"\n",
    "sql_query_2 = ask_ollama_for_sql(store, user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2422fd-06a4-44e8-9679-a8f49320867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.query(sql_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27984b-d48e-4628-97c4-a9e4f9868fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c74da62-0479-4a2b-8040-ba05e2fadf2e",
   "metadata": {},
   "source": [
    "## Use Generic AI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3312579f-9deb-4aa2-82d9-1c1cfed0e83d",
   "metadata": {},
   "source": [
    "This will ingest the data too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b66d1-cd2c-431f-87a1-caa4a6869962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = store.get_table(\"wildfiredata\", collection = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07966aed-f754-483f-b031-e656f3646de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    OpenAI(temperature=0), \n",
    "    df, \n",
    "    verbose=False,\n",
    "    allow_dangerous_code=True) # the real data is in the database anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a13a4-ec26-4caa-bf0b-da2beb098451",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"how many wind speeds are above 10?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362f279-8518-46c0-86e6-27bd5a514277",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "agent.invoke(\"plot a scatter graph or wind_speed vs safe_unsafe_fire_behavior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6e8b1-689a-4db0-ba6f-ce8b492bce2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv__dsi_dev",
   "language": "python",
   "name": "venv__dsi_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
