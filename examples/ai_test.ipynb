{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc40f15-82c6-4bfc-a629-cb023afa3a3f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f80ba9-0f82-4c55-a5ae-6a09b8540730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io, contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d102c-8609-47e6-a8ab-9b0aec4d9e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install in your environment\n",
    "!{sys.executable} -m pip install langchain openai\n",
    "!{sys.executable} -m pip install langchain_community openai\n",
    "!{sys.executable} -m pip install --upgrade langchain langchain_community openai\n",
    "!{sys.executable} -m pip install --upgrade langchain langchain-openai openai\n",
    "!{sys.executable} -m pip install -U langchain-ollama\n",
    "\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251a2a6-1ef1-4d45-9299-b14aea7b76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsi.dsi import DSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6623f4-8d71-4035-8066-b9a3bf1ad947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96841c0c-9a8f-4f1b-b526-ce5e5392302e",
   "metadata": {},
   "source": [
    "## AI Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acdfea-4ace-4d8a-95d0-2bec692179e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to ask chatgpt for queries\n",
    "def ask_chatgpt_for_sql(store, user_request, open_ai_key, model_name=\"gpt-5\"):\n",
    "    # Get schema\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf):\n",
    "        if store.backend_name == 'sqlite':\n",
    "            store.query(\"SELECT name, type, sql FROM sqlite_master WHERE sql NOT NULL ORDER BY type, name\")\n",
    "        else:\n",
    "            store.query(\"SELECT table_name AS name, table_type AS type FROM information_schema.tables WHERE table_schema = 'main' ORDER BY table_type, table_name\")\n",
    "    query_output_str = buf.getvalue()\n",
    "    schema = query_output_str.rsplit(\"|\", 1)[-1].strip()\n",
    "    \n",
    "    # Set key\n",
    "    os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "    \n",
    "    # Use LLM to extract queries\n",
    "    prompt_template = (\n",
    "        \"You are an expert in SQL assistant.\\n\"\n",
    "        \"Here is the schema:\\n{schema}\\n\\n\"\n",
    "        \"Generate a SQL query for the following request:\\n{user_request}\\n\\n\"\n",
    "        \"Only output the SQL query on one line please.\"\n",
    "    )\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"schema\", \"user_request\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=0)\n",
    "    \n",
    "    # Create the chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\n",
    "        \"schema\": schema, \n",
    "        \"user_request\": user_request\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d5a00-ff13-445a-a31d-05e2c52114c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama_for_sql(store, user_request, model_name=\"mistral:latest\"):\n",
    "    # Get schema\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf):\n",
    "        if store.backend_name == 'sqlite':\n",
    "            store.query(\"SELECT name, type, sql FROM sqlite_master WHERE sql NOT NULL ORDER BY type, name\")\n",
    "        else:\n",
    "            store.query(\"SELECT table_name AS name, table_type AS type FROM information_schema.tables WHERE table_schema = 'main' ORDER BY table_type, table_name\")\n",
    "    query_output_str = buf.getvalue()\n",
    "    schema = query_output_str.rsplit(\"|\", 1)[-1].strip()\n",
    "\n",
    "    # Use LLM to extract queries\n",
    "    prompt_template = (\n",
    "        \"You are an expert SQL assistant.\\n\"\n",
    "        \"Here is the schema:\\n{schema}\\n\\n\"\n",
    "        \"Generate a SQL query for the following request:\\n{user_request}\\n\\n\"\n",
    "        \"Only output the SQL query on one line please.\"\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"schema\", \"user_request\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "\n",
    "    # Initialize the local chat model served by Ollama\n",
    "    llm = ChatOllama(model=model_name, temperature=0)\n",
    "\n",
    "    # LCEL chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # NOTE: your original snippet had {user_query}; use user_request instead.\n",
    "    response = chain.invoke({\n",
    "        \"schema\": schema,\n",
    "        \"user_request\": user_request\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "212be803-a4f1-47bf-8f40-af6773642cee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdd15ea-bc34-4960-b848-97cd9a28d1a3",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d50037-0ff0-4ddf-8861-1753847627fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = DSI(backend_name = \"Sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4451bb-b19a-4629-9822-7ad49062725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.read(\"wildfire/wildfiredata.csv\", 'CSV', table_name='wildfiredata')\n",
    "store.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53e84be7-84a9-4241-b4e6-9dc9e1dbd1e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13c00094-1956-4359-9644-8dc186db89e5",
   "metadata": {},
   "source": [
    "# Use AI to extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aec268-76ac-44f2-868d-9f633cf231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Find all entries where wind speed is above 10\"\n",
    "sql_query_1 = ask_chatgpt_for_sql(store, user_question, os.getenv(\"OPENAI_API_KEY\"),  model_name=\"gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade020ef-65a1-4c5d-8521-cccfe5b08dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store.query(sql_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce549548-b383-40cf-b4f4-106f79499145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3fe36-84c1-4e60-bb66-8ba352407738",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Find all entries where wind speed is above 10 and show it in ascending order of burned area size, and show only the top 5\"\n",
    "sql_query_2 = ask_ollama_for_sql(store, user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2422fd-06a4-44e8-9679-a8f49320867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.query(\"SELECT * FROM wildfiredata WHERE wind_speed > 10 ORDER BY burned_area ASC LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27984b-d48e-4628-97c4-a9e4f9868fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv__dsi_dev",
   "language": "python",
   "name": "venv__dsi_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
